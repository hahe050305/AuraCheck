<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AuraCheck Mobile | V12.9</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.js" crossorigin="anonymous"></script>
    <style>
        :root {
            --bg-neutral: #0f172a; --bg-happy: #064e3b; --bg-sad: #1e3a8a; 
            --bg-frustrated: #7f1d1d; --bg-surprised: #78350f; --bg-focused: #1e293b; --bg-thinking: #334155;
        }
        body { 
            margin: 0; font-family: system-ui, -apple-system; 
            background: var(--bg-neutral); color: #fff; overflow: hidden;
            transition: background 1.2s ease;
        }
        #app { display: flex; flex-direction: column; align-items: center; justify-content: space-around; height: 100vh; padding: 20px; box-sizing: border-box; }
        
        .view-box { 
            position: relative; width: 75vw; height: 75vw; max-width: 300px; max-height: 300px;
            border-radius: 50%; overflow: hidden; border: 3px solid rgba(255,255,255,0.15);
            box-shadow: 0 0 40px rgba(0,0,0,0.5); background: #000;
        }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }
        
        #label { 
            padding: 10px 25px; border-radius: 30px; background: rgba(0,0,0,0.7);
            backdrop-filter: blur(12px); font-weight: 800; letter-spacing: 3px;
            border: 1px solid rgba(255,255,255,0.1); margin-top: -30px; z-index: 10;
        }
        
        .info-panel { text-align: center; }
        #advice { font-size: 1.1rem; font-weight: 500; margin-bottom: 5px; min-height: 1.5em; color: #e2e8f0; }
        .engine-tag { font-size: 0.6rem; letter-spacing: 4px; opacity: 0.4; text-transform: uppercase; }
        
        #capture { 
            width: 70%; padding: 16px; border-radius: 40px; border: none;
            background: rgba(255,255,255,0.9); color: #000; font-weight: 800;
            transition: 0.2s;
        }
        .loader { position: fixed; inset: 0; background: #0f172a; display: flex; align-items: center; justify-content: center; z-index: 100; text-align: center; }
    </style>
</head>
<body>
    <div id="loading" class="loader"><div><b style="letter-spacing:5px">AURA V12.9</b><br><small id="status">INIT ENGINE...</small></div></div>

    <div id="app">
        <div class="view-box" id="glow">
            <video id="webcam" autoplay playsinline muted></video>
        </div>
        <div id="label">SYNCING</div>

        <div class="info-panel">
            <div id="advice">Initializing sensors...</div>
            <div class="engine-tag">Mobile Adaptive Logic</div>
        </div>

        <button id="capture">GENERATE REPORT</button>
    </div>

<script type="module">
    import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const UI = {
        Neutral: { color: "#0f172a", label: "NEUTRAL", info: "Biometric Equilibrium." },
        Happy: { color: "#064e3b", label: "HAPPY", info: "High Positivity Resonance." },
        Sad: { color: "#1e3a8a", label: "SAD", info: "Introspective Frequency." },
        Frustrated: { color: "#7f1d1d", label: "FRUSTRATED", info: "Internal Tension Detected." },
        Surprised: { color: "#78350f", label: "SURPRISED", info: "Rapid Sensory Expansion." },
        Thinking: { color: "#334155", label: "THINKING", info: "Analyzing Variables..." },
        Focused: { color: "#1e293b", label: "FOCUSED", info: "Deep Concentration Mode." }
    };

    let faceLandmarker, video = document.getElementById("webcam");
    let currentAura = "Neutral", history = [], isCalibrated = false, baseline = {}, frames = 0;

    async function start() {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
        faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
            baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task", delegate: "GPU" },
            outputFaceBlendshapes: true, runningMode: "VIDEO", numFaces: 1
        });
        
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        video.srcObject = stream;
        video.onloadeddata = () => { document.getElementById("loading").style.display = "none"; loop(); };
    }

    function loop() {
        const result = faceLandmarker.detectForVideo(video, performance.now());
        if (result.faceBlendshapes?.length > 0) {
            const s = {};
            result.faceBlendshapes[0].categories.forEach(c => s[c.categoryName] = c.score);
            const l = result.faceLandmarks[0];

            if (!isCalibrated) {
                for (let k in s) baseline[k] = (baseline[k] || 0) + (s[k] / 40);
                frames++; if (frames >= 40) isCalibrated = true;
            } else {
                let detect = "Neutral";
                
                // 1. ORIENTATION (Thinking Logic)
                const yaw = Math.abs(l[4].x - (l[234].x + l[454].x)/2);  // Left/Right
                const pitch = Math.abs(l[4].y - (l[10].y + l[152].y)/2); // Up/Down
                
                // 2. MOUTH PRESS (Focused Logic)
                const mouthPress = s.mouthPressLeft + s.mouthPressRight + s.mouthPucker;

                if (mouthPress > 0.45) {
                    detect = "Focused"; // Mouth compression (finger on lips style) takes priority
                } else if (yaw > 0.20 || pitch > 0.20) {
                    detect = "Thinking"; // Head tilt override
                } else {
                    // 3. EMOTION CLUSTERS
                    const smile = s.mouthSmileLeft > 0.70;
                    const wide = s.eyeWideLeft > 0.28 || s.jawOpen > 0.45;
                    const frown = s.browDownLeft > 0.28;
                    
                    // SADNESS: Inner rise OR (mouth droop + relaxed brows)
                    const sadBrow = (s.browInnerUp - baseline.browInnerUp) > 0.38;
                    const sadMouth = s.mouthFrownLeft > 0.35 || s.mouthLowerDownLeft > 0.25;

                    if (wide && !frown) detect = "Surprised";
                    else if (smile) detect = "Happy";
                    else if (frown && !wide) detect = "Frustrated";
                    else if (sadBrow || (sadMouth && !frown)) detect = "Sad";
                }

                updateHistory(detect);
            }
        }
        requestAnimationFrame(loop);
    }

    function updateHistory(detect) {
        history.push(detect);
        if (history.length > 35) history.shift(); // ~1.1s buffer

        const counts = history.reduce((a, b) => (a[b] = (a[b] || 0) + 1, a), {});
        const top = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);

        // Transition Logic: Entry (18/35 frames), Exit (30/35 frames)
        if (currentAura === "Neutral") {
            if (top !== "Neutral" && counts[top] >= 18) apply(top);
        } else {
            if (top === "Neutral" && counts[top] >= 30) apply("Neutral");
            else if (top !== "Neutral" && top !== currentAura && counts[top] >= 18) apply(top);
        }
    }

    function apply(type) {
        currentAura = type;
        const data = UI[type];
        document.body.style.background = data.color;
        document.getElementById("label").innerText = data.label;
        document.getElementById("advice").innerText = data.info;
        document.getElementById("glow").style.boxShadow = `0 0 40px ${data.color}`;
    }

    start();
</script>
</body>
</html>
